import numpy as np 
from sklearn.datasets import fetch_olivetti_faces 
from sklearn.naive_bayes import GaussianNB 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score, classification_report 
from sklearn.decomposition import PCA 
import matplotlib.pyplot as plt 
 
# Load the Olivetti Faces dataset 
olivetti = fetch_olivetti_faces() 
X = olivetti.data #Stores the face images as data points (features). 
y = olivetti.target # Stores the corresponding labels (person's identity)  
                    #for each face image. 
 
print(f"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features,   
      {len(np.unique(y))} classes") 
 
# Split the dataset into training and testing sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,  
                                   random_state=42, stratify=y) 
 
print(f"Training set size: {X_train.shape[0]}") 
print(f"Test set size: {X_test.shape[0]}") 
 
# Apply PCA for dimensionality reduction  
n_components = 100   
pca = PCA(n_components=n_components, whiten=True, random_state=42) 
X_train_pca = pca.fit_transform(X_train) 
X_test_pca = pca.transform(X_test) 
 
print(f"Reduced dimensions after PCA: {X_train_pca.shape[1]}") 
 
# Initialize and train the Gaussian Naive Bayes classifier 
gnb = GaussianNB() 
gnb.fit(X_train_pca, y_train) 
 
# Make predictions on the test set 
y_pred = gnb.predict(X_test_pca) 
 
# Calculate accuracy 
accuracy = accuracy_score(y_test, y_pred) 
print(f"\nAccuracy: {accuracy:.2%}") 
 
 
 
# Print classification report 
print("\nClassification Report:") 
print(classification_report(y_test, y_pred)) 
# Visualize some test results 
plt.figure(figsize=(10, 8)) 
for i in range(12): 
plt.subplot(3, 4, i+1) 
plt.imshow(X_test[i].reshape(64, 64), cmap='gray') 
plt.title(f"True: {y_test[i]}\nPred: {y_pred[i]}") 
plt.axis('off') 
plt.tight_layout() 
plt.show()
